监控声音
# -*- coding: utf-8 -*-
import pyaudio
import wave
import numpy as np

def Monitor():
    CHUNK = 512
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 48000
    RECORD_SECONDS = 5
    WAVE_OUTPUT_FILENAME = "cache.wav"
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT,
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)
    print("开始缓存录音")
    frames = []
    while (True):
        print 'begin '
        for i in range(0, 100):
            data = stream.read(CHUNK)
            frames.append(data)
        audio_data = np.fromstring(data, dtype=np.short)
        large_sample_count = np.sum( audio_data > 800 )
        temp = np.max(audio_data)
        if temp > 800 :
            print "检测到信号"
            print '当前阈值：',temp 
            break
    stream.stop_stream()
    stream.close()
    p.terminate()
    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(p.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

if __name__ == '__main__':
    Monitor()
    
播放
#-*-coding:utf-8-*-

#引入库
import pyaudio
import wave
import sys

# 定义数据流块
CHUNK = 1024

if len(sys.argv) < 2:
    print("Plays a wave file.\n\nUsage: %s filename.wav" % sys.argv[0])
    sys.exit(-1)

# 只读方式打开wav文件
wf = wave.open(r'D:\\Python\\Lib\\site-packages\\PyQt4\\uic\\test.wav', 'rb')#(sys.argv[1], 'rb')

p = pyaudio.PyAudio()

# 打开数据流
stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),
                channels=wf.getnchannels(),
                rate=wf.getframerate(),
                output=True)

# 读取数据
data = wf.readframes(CHUNK)

# 播放  
while data != '':
    stream.write(data)
    data = wf.readframes(CHUNK)

# 停止数据流  
stream.stop_stream()
stream.close()

# 关闭 PyAudio  
p.terminate()  

录音
import pyaudio
import wave

CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 2
RATE = 44100
RECORD_SECONDS = 5
WAVE_OUTPUT_FILENAME = "output.wav"

p = pyaudio.PyAudio()

stream = p.open(format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK)

print("* recording")

frames = []

for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):
    data = stream.read(CHUNK)
    frames.append(data)

print("* done recording")

stream.stop_stream()
stream.close()
p.terminate()

wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')
wf.setnchannels(CHANNELS)
wf.setsampwidth(p.get_sample_size(FORMAT))
wf.setframerate(RATE)
wf.writeframes(b''.join(frames))
wf.close()

回放
import pyaudio

CHUNK = 1024
WIDTH = 2
CHANNELS = 2
RATE = 44100
RECORD_SECONDS = 5

p = pyaudio.PyAudio()

stream = p.open(format=p.get_format_from_width(WIDTH),
                channels=CHANNELS,
                rate=RATE,
                input=True,
                output=True,
                frames_per_buffer=CHUNK)

print("* recording")

for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):
    data = stream.read(CHUNK)
    stream.write(data, CHUNK)

print("* done")

stream.stop_stream()
stream.close()

p.terminate()
回调
import pyaudio
import wave
import time
import sys

if len(sys.argv) < 2:
    print("Plays a wave file.\n\nUsage: %s filename.wav" % sys.argv[0])
    sys.exit(-1)

wf = wave.open(sys.argv[1], 'rb')

p = pyaudio.PyAudio()

def callback(in_data, frame_count, time_info, status):
    data = wf.readframes(frame_count)
    return (data, pyaudio.paContinue)

stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),
                channels=wf.getnchannels(),
                rate=wf.getframerate(),
                output=True,
                stream_callback=callback)

stream.start_stream()

while stream.is_active():
    time.sleep(0.1)

stream.stop_stream()
stream.close()
wf.close()

p.terminate()
非阻塞回调
import pyaudio
import time

WIDTH = 2
CHANNELS = 2
RATE = 44100

p = pyaudio.PyAudio()

def callback(in_data, frame_count, time_info, status):
    return (in_data, pyaudio.paContinue)

stream = p.open(format=p.get_format_from_width(WIDTH),
                channels=CHANNELS,
                rate=RATE,
                input=True,
                output=True,
                stream_callback=callback)

stream.start_stream()

while stream.is_active():
    time.sleep(0.1)

stream.stop_stream()
stream.close()

p.terminate()

又一实例
import wave
from pyaudio import PyAudio,paInt16

framerate=16000
NUM_SAMPLES=2000
chunk=2014
channels=1
sampwidth=2
TIME=20 #ms

#保存
def save_wave_file(filename,data):

    '''save the date to the wavfile'''
    wf=wave.open(filename,'wb')
    wf.setnchannels(channels)
    wf.setsampwidth(sampwidth)
    wf.setframerate(framerate)
    wf.writeframes(b"".join(data))
    wf.close()

#录音
def my_record():

    pa=PyAudio()
    stream=pa.open(format = paInt16,channels=1,
                   rate=framerate,input=True,
                   frames_per_buffer=NUM_SAMPLES)
    my_buf=[]
    count=0
    
    while count<TIME:
        string_audio_data = stream.read(NUM_SAMPLES)
        my_buf.append(string_audio_data)
        count+=1
        print('.')
        
    save_wave_file('01.wav',my_buf)
    stream.close()

#播放
def play():

    wf=wave.open(r"my.wav",'rb')
    p=PyAudio()
    stream=p.open(format=p.get_format_from_width(wf.getsampwidth()),
				 channels=    wf.getnchannels()
				 rate=wf.getframerate(),
			     output=True)
			     
    data=wf.readframes(chunk)
  	while len(data) > 0:
	    stream.write(data)
	    data = wf.readframes(CHUNK)
	    
	stream.stop_stream()
    stream.close()
    
    p.terminate()

if __name__ == '__main__':
    my_record()
    print('Over!') 
    play()

监测录音
# !/usr/bin/env python
# -*- coding: utf-8 -*-
import pyaudio
import wave
import time
import numpy as np
import matplotlib.pyplot as plt
def Monitor():
    CHUNK = 512
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    RECORD_SECONDS = 5
    ly=1
    WAVE_OUTPUT_FILENAME = "acache.wav"
    p = pyaudio.PyAudio()
    stream = p.open(format=p.get_format_from_width(2),
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    frames_per_buffer=CHUNK)
    print("ok")
    frames = []
    while (1):
      isly=0
      frames.clear()
      while(1):
        ly=0
        for i in range(0, int(RATE/CHUNK*2)):
          data = stream.read(CHUNK)
          frames.append(data)
          audio_data = np.fromstring(data, dtype=np.short)
          #large_sample_count = np.sum( audio_data > 800 )
          #time = np.arange(0, RATE) * (1.0 / RATE)
          temp = np.max(audio_data)
          print(temp)
          if(temp>800):
            ly=1
            isly=1
        if(ly==0):
          break
      if(isly==0):
        continue
      print('ok....')
      time.sleep(2)
      #stream.stop_stream()
      #stream.close()
      #p.terminate()
      wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')
      wf.setnchannels(CHANNELS)
      wf.setsampwidth(p.get_sample_size(FORMAT))
      wf.setframerate(RATE)
      wf.writeframes(b''.join(frames))
      wf.close()

if __name__ == '__main__':
    Monitor()


混合使用 建议用webrtsvad 监测语音 10   20   30 ms
# !/usr/bin/env python
# -*- coding: gbk -*-
import pyaudio
import wave
import time
import requests
import json
import sys
import numpy as np
from aip import AipSpeech
APP_ID = '18154448'

API_KEY = 'z43T3yP40WyplTDQFfvIabpg'

SECRET_KEY = 'iLDNxFHViyQdHuF4phzV76Rf86gya1iy'

def sound2text(file_path='test.wav'):
    client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)
    with open(file_path, 'rb') as fp:
       recog=client.asr(fp.read(), 'wav', 16000)
    text=recog.get('result')[0]
    #print(recog)
    #print(text)
    return text
def text2sound(words='ddd'):
  CHUNK = 512
  client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)

  result = client.synthesis(words, 'zh', 1, {'vol': 6, 'aue': 6,'spd':1, 'per': 4}) 

  if not isinstance(result, dict):
    with open('test.wav', 'wb') as f:
        f.write(result)
    f.close
    wf = wave.open(r'test.wav', 'rb')
    p=pyaudio.PyAudio()
    stream=p.open(format=p.get_format_from_width(2),
		  channels=1,
		  rate=16000,
		  output=True)
			     
    data=wf.readframes(CHUNK)
    while len(data) > 0:
      stream.write(data)
      data = wf.readframes(CHUNK)
    stream.stop_stream()
    stream.close()
    p.terminate()
    return True
  else:
    return False
  
def Monitor():
    CHUNK = 512
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000
    RECORD_SECONDS = 5
    ly=1
    WAVE_OUTPUT_FILENAME = "acache.wav"
    p = pyaudio.PyAudio()
    stream = p.open(format=p.get_format_from_width(2),
                    channels=CHANNELS,
                    rate=RATE,
                    input=True,
                    output=True,
                    frames_per_buffer=CHUNK)
    
    rframes = []
    frames = []
    wf = wave.open(r'test.wav', 'rb')
    rdata=wf.readframes(CHUNK)
    while len(rdata) > 0:
      stream.write(rdata)
      rdata = wf.readframes(CHUNK)
    while (1):
      isly=0
      frames.clear()
      while(1):
        ly=0
        for i in range(0, int(RATE/CHUNK*2)):
          data = stream.read(CHUNK)
          frames.append(data)
          #stream.write(data, CHUNK)
          audio_data = np.fromstring(data, dtype=np.short)
          #large_sample_count = np.sum( audio_data > 800 )
          #time = np.arange(0, RATE) * (1.0 / RATE)
          temp = np.max(audio_data)
          print(temp,)
          if(temp>800):
            ly=1
            isly=1
        if(ly==0):
          break
      if(isly==0):
        continue
      text2sound('开始转换')
      time.sleep(3)
      #stream.stop_stream()
      #stream.close()
      #p.terminate()
      wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')
      wf.setnchannels(CHANNELS)
      wf.setsampwidth(p.get_sample_size(FORMAT))
      wf.setframerate(RATE)
      wf.writeframes(b''.join(frames))
      wf.close()
      text2sound('你说的是')
      wf = wave.open(r'test.wav', 'rb')
      rdata=wf.readframes(CHUNK)
      while len(rdata) > 0:
       stream.write(rdata)
       rdata = wf.readframes(CHUNK)
      wf.close()
if __name__ == '__main__':
    #Monitor()
    #print(sound2text("test.wav"))
    text2sound('你说的是:'+sound2text("test.wav"))
